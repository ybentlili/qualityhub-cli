# ğŸ” QualityHub CLI

[![npm version](https://img.shields.io/npm/v/qualityhub-cli.svg)](https://www.npmjs.com/package/qualityhub-cli)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Node.js](https://img.shields.io/badge/Node.js-18+-green.svg)](https://nodejs.org/)

**Know if your release is safe to deploy â€” in 2 seconds.**

QualityHub CLI parses your test results, analyzes quality trends, detects regressions, and gives you a clear risk score with a go/no-go decision. Works locally, in CI/CD, and on merge requests.

<!-- TODO: replace with your actual GIF -->
![QualityHub CLI Demo](docs/demo.gif)

---

## âš¡ Quick Start

```bash
# Install
npm install -g qualityhub-cli

# Run your tests, then:
qualityhub parse jest ./coverage
qualityhub analyze
```

That's it. No account, no config, no server needed.

---

## ğŸ¯ What You Get

```
ğŸ” QualityHub Analysis
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Project:  my-app@2.3.1
   Branch:   main
   Commit:   a3f4d2c

   ğŸ“Š Tests
      âŒ 243/250 passed (97.2%)
      âŒ 4 failed
      â­ï¸  3 skipped
      â±ï¸  Duration: 12.7s

   ğŸ“ˆ Coverage
      Lines:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 87.3%  â–¼ -3.2%
      Branches:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 82.2%
      Functions:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 91.3%

   ğŸš¨ Issues Detected
      ğŸŸ¡ 4 tests failed (97.2% pass rate)
      ğŸ² 2 flaky tests detected
      ğŸ“‰ Coverage dropped 3.2% since last run
      ğŸ†• 2 new test failures since last run

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ğŸ¯ Risk Score:  âš ï¸ 72/100 (MEDIUM RISK)
   ğŸ“‹ Decision:    âš ï¸  CAUTION â€” Review issues before deploying
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## âœ¨ Features

- **ğŸ” Instant analysis** â€” Risk score + go/no-go decision in seconds
- **ğŸ“‰ Regression detection** â€” Automatically compares with previous runs
- **ğŸ² Flaky test detection** â€” Identifies slow/unreliable tests
- **ğŸ“Š Coverage tracking** â€” Lines, branches, functions with trend deltas
- **ğŸ“ Markdown reports** â€” Post analysis directly on GitLab MRs / GitHub PRs
- **ğŸ”Œ Multi-framework** â€” Jest, JUnit, JaCoCo out of the box
- **âš¡ Zero config** â€” Works instantly, no server required

---

## ğŸ“– Usage

### 1. Parse your test results

```bash
# JavaScript / TypeScript (Jest)
qualityhub parse jest ./coverage

# Java / Kotlin (JaCoCo + JUnit)
qualityhub parse jacoco ./target/site/jacoco/jacoco.xml
qualityhub parse junit ./target/surefire-reports

# With project metadata
qualityhub parse jest ./coverage \
  --project my-app \
  --version 2.3.1 \
  --commit a3f4d2c \
  --branch main
```

### 2. Analyze

```bash
# Terminal output (default)
qualityhub analyze

# Markdown output (for MR/PR comments)
qualityhub analyze --format markdown

# Save markdown to file
qualityhub analyze --format markdown --output report.md
```

### 3. Push to QualityHub (optional)

```bash
qualityhub push qa-result.json
```

---

## ğŸ”„ CI/CD Integration

### GitLab CI

```yaml
quality-check:
  stage: test
  script:
    - npm test -- --coverage
    - npx qualityhub-cli parse jest ./coverage
    - npx qualityhub-cli analyze
  cache:
    paths:
      - .qualityhub/   # Persist history between runs
  artifacts:
    when: always
    paths:
      - qa-result.json
```

### GitHub Actions

```yaml
- name: Quality Check
  run: |
    npm test -- --coverage
    npx qualityhub-cli parse jest ./coverage
    npx qualityhub-cli analyze

- name: Cache QualityHub history
  uses: actions/cache@v3
  with:
    path: .qualityhub
    key: qualityhub-${{ github.ref }}
```

The CLI exits with code 1 when the decision is **BLOCK**, so your pipeline fails automatically on critical quality issues.

---

## ğŸ“ Markdown Reports for Merge Requests

Generate a markdown report to post on your MR/PR:

```bash
qualityhub analyze --format markdown
```

Output:

| Metric | Value | Delta |
|--------|-------|-------|
| âŒ Tests | 243/250 passed (97.2%) | â€” |
| ğŸ“ˆ Line Coverage | 87.3% | â–¼ -3.2% |
| ğŸ”€ Branch Coverage | 82.2% | â€” |
| âš™ï¸ Function Coverage | 91.3% | â€” |
| â±ï¸ Duration | 12.7s | +15% |

> ğŸš¨ **2 issues detected** â€” 4 tests failed, 2 flaky tests

---

## ğŸ“‰ Automatic Regression Detection

QualityHub stores run history locally in `.qualityhub/history.json`. On every run, it compares with the previous analysis and detects:

- **Coverage drops** â€” "Coverage decreased 3.2% since last run"
- **New test failures** â€” "2 new test failures since last run"
- **Build slowdowns** â€” "Build time increased 18%"
- **Removed tests** â€” "12 tests removed since last run"

No server needed. History persists across runs.

---

## ğŸ¨ Supported Frameworks

| Framework | Language | Coverage | Tests |
|-----------|----------|----------|-------|
| **Jest** | JavaScript / TypeScript | âœ… | âœ… |
| **JaCoCo** | Java / Kotlin | âœ… | â€” |
| **JUnit** | Java / Kotlin / Python | â€” | âœ… |

More coming soon: pytest, XCTest, Go test, Rust.

---

## ğŸ“„ qa-result.json Format

QualityHub uses an open standard format for quality metrics:

```json
{
  "version": "1.0.0",
  "project": {
    "name": "my-app",
    "version": "2.3.1",
    "commit": "a3f4d2c",
    "branch": "main",
    "timestamp": "2026-02-17T20:00:00Z"
  },
  "quality": {
    "tests": {
      "total": 250,
      "passed": 243,
      "failed": 4,
      "skipped": 3,
      "duration_ms": 12700,
      "flaky_tests": ["Metrics API > should handle concurrent uploads"]
    },
    "coverage": {
      "lines": 87.3,
      "branches": 82.2,
      "functions": 91.3,
      "statements": 88.7
    }
  }
}
```

Any tool that outputs this format works with QualityHub. [Create your own adapter â†’](docs/creating-adapter.md)

---

## ğŸ”§ All Commands

| Command | Description |
|---------|-------------|
| `qualityhub init` | Initialize QualityHub in current directory |
| `qualityhub parse <format> <path>` | Parse test results â†’ `qa-result.json` |
| `qualityhub analyze` | Analyze and show risk assessment |
| `qualityhub analyze --format markdown` | Output as Markdown (for MR comments) |
| `qualityhub analyze --format markdown -o report.md` | Save Markdown to file |
| `qualityhub push <file>` | Push results to QualityHub server |

---

## ğŸ§ª Try It Now

```bash
# Clone and test with example data
git clone https://github.com/ybentlili/qualityhub-cli
cd qualityhub-cli
npm install && npm run build && npm link

# Parse example Jest results
qualityhub parse jest ./examples/jest

# See the analysis
qualityhub analyze

# See it as Markdown
qualityhub analyze --format markdown
```

---

## ğŸ—ºï¸ Roadmap

- [x] Parse Jest, JaCoCo, JUnit
- [x] Risk score + go/no-go decision
- [x] Local history + regression detection
- [x] Markdown reports for MR/PR
- [ ] Auto-comment on GitLab MR / GitHub PR
- [ ] pytest adapter
- [ ] SonarQube integration
- [ ] AI-powered risk analysis (coming soon)

---

## ğŸ”— Links

- **GitHub**: [ybentlili/qualityhub-cli](https://github.com/ybentlili/qualityhub-cli)
- **npm**: [qualityhub-cli](https://www.npmjs.com/package/qualityhub-cli)
- **Main project**: [ybentlili/qualityhub](https://github.com/ybentlili/qualityhub)

---

## ğŸ“ License

MIT â€” see [LICENSE](LICENSE)

---

## ğŸ¤ Contributing

Contributions welcome! The easiest way to help:

- **Add an adapter** â€” pytest, XCTest, Go test, Rust
- **Report bugs** â€” [Open an issue](https://github.com/ybentlili/qualityhub-cli/issues)
- **Star the repo** â€” It helps visibility â­

See [CONTRIBUTING.md](CONTRIBUTING.md) for details.